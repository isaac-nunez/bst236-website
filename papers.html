<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Papers</title>
    <link rel="stylesheet" href="styles/style.css">
</head>
<body>
    <div class="dog-container">
        <img src="images/dog.jpg" alt="My dog" class="dog-image">
        <p class="dog-caption">The guardian is observing</p>
    </div>
    <header>
        <h1>Papers</h1>
        <nav>
            <ul>
                <li><a href="main.html">Main (regular stuff)</a></li>
                <li><a href="games.html">Games (fun stuff)</a></li>
                <li><a href="papers.html">Papers (sciency stuff)</a></li>
                <li><a href="temperatures.html">Temperatures</a></li>
            </ul>
        </nav>
    </header>
    <main>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section id="papers-section">
            <h2>Latest Papers in Causal Inference</h2>
            <ul id="papersList">
                <li>
                    <h3>Reionization and the Hubble Constant: Correlations in the Cosmic
  Microwave Background</h3>
                    <p><strong>Authors:</strong> Itamar J. Allali, Praniti Singh, JiJi Fan, Lingfeng Li</p>
                    <p>  Recently, the James Webb Space Telescope (JWST) has found early galaxies
producing photons from more efficient ionization than previously assumed. This
may suggest a reionization process with a larger reionization optical depth,
$\tau_{\rm reio}$, in some mild disagreement with that inferred from
measurements of cosmic microwave background (CMB). Intriguingly, the CMB would
prefer larger values of $\tau_{\rm reio}$, more consistent with the recent JWST
hint, if the large-scale measurements (i.e. $\ell <30$) of E-mode polarization
are removed. In addition, $\tau_{\rm reio}$ has an indirect correlation with
today's Hubble constant $H_0$ in $\Lambda$CDM. Motivated by these interesting
observations, we investigate and reveal the underlying mechanism for this
correlation, using the CMB dataset without the low-$\ell$ polarization data as
a proxy for a potential cosmology with a larger $\tau_{\rm reio}$. We further
explore how this correlation may impact the Hubble tension between early and
late universe measurements of $H_0$, in $\Lambda$CDM as well as two proposals
to alleviate the Hubble tension: the dark radiation (DR) and early dark energy
(EDE) models. We find that the Hubble tension gets further reduced mildly for
almost all cases due to the larger $\tau_{\rm reio}$ and its positive
correlation with $H_0$, with either the Baryon Acoustic Oscillations (BAO) data
before those from the Dark Energy Spectroscopic Instrument (DESI) or the DESI
data.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.05691v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/7/2025</p>
                </li>
                <li>
                    <h3>Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for
  Heterogeneous Reasoning</h3>
                    <p><strong>Authors:</strong> Justin Chih-Yao Chen, Sukwon Yun, Elias Stengel-Eskin, Tianlong Chen, Mohit Bansal</p>
                    <p>  Combining existing pre-trained expert LLMs is a promising avenue for scalably
tackling large-scale and diverse tasks. However, selecting experts at the task
level is often too coarse-grained, as heterogeneous tasks may require different
expertise for each instance. To enable adaptive instance-level mixing of
pre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and
gradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained
approach to selection by emphasizing skills, e.g., algebra in math or molecular
biology in biomedical reasoning. We propose a skill-based recruiting strategy
that dynamically selects the most relevant set of expert LLMs for diverse
reasoning tasks based on their strengths. Each selected expert then generates
its own reasoning, resulting in k outputs from k experts, which are then
synthesized into a final high-quality response by an aggregator chosen based on
its ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's
instance-level expert selection improves performance by a large margin but --
when implemented naively -- can introduce a high computational overhead due to
the need for constant model loading and offloading. To address this, we
implement a batch inference strategy that groups instances based on their
assigned experts, loading each model only once. This allows us to integrate 16
expert models on 1 GPU with a time cost comparable to or better than prior
multi-agent baselines using 4 GPUs. Through extensive evaluations on diverse
benchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we demonstrate that
Symbolic-MoE outperforms strong LLMs like GPT4o-mini, as well as multi-agent
approaches, with an absolute average improvement of 8.15% over the best
multi-agent baseline. Moreover, Symbolic-MoE removes the need for expensive
multi-round discussions, outperforming discussion baselines with less
computation.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.05641v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/7/2025</p>
                </li>
                <li>
                    <h3>Integration of aggregated data in causally interpretable meta-analysis
  by inverse weighting</h3>
                    <p><strong>Authors:</strong> Tat-Thang Vo, Tran Trong Khoi Le, Sivem Afach, Stijn Vansteelandt</p>
                    <p>  Obtaining causally interpretable meta-analysis results is challenging when
there are differences in the distribution of effect modifiers between eligible
trials. To overcome this, recent work on transportability methods has
considered standardizing results of individual studies over the case-mix of a
target population, prior to pooling them as in a classical random-effect
meta-analysis. One practical challenge, however, is that case-mix
standardization often requires individual participant data (IPD) on outcome,
treatments and case-mix characteristics to be fully accessible in every
eligible study, along with IPD case-mix characteristics for a random sample
from the target population. In this paper, we aim to develop novel strategies
to integrate aggregated-level data from eligible trials with non-accessible IPD
into a causal meta-analysis, by extending moment-based methods frequently used
for population-adjusted indirect comparison in health technology assessment.
Since valid inference for these moment-based methods by M-estimation theory
requires additional aggregated data that are often unavailable in practice,
computational methods to address this concern are also developed. We assess the
finite-sample performance of the proposed approaches by simulated data, and
then apply these on real-world clinical data to investigate the effectiveness
of risankizumab versus ustekinumab among patients with moderate to severe
psoriasis.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.05634v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/7/2025</p>
                </li>
                <li>
                    <h3>Conformal Prediction for Image Segmentation Using Morphological
  Prediction Sets</h3>
                    <p><strong>Authors:</strong> Luca Mossina, Corentin Friedrich</p>
                    <p>  Image segmentation is a challenging task influenced by multiple sources of
uncertainty, such as the data labeling process or the sampling of training
data. In this paper we focus on binary segmentation and address these
challenges using conformal prediction, a family of model- and data-agnostic
methods for uncertainty quantification that provide finite-sample theoretical
guarantees and applicable to any pretrained predictor. Our approach involves
computing nonconformity scores, a type of prediction residual, on held-out
calibration data not used during training. We use dilation, one of the
fundamental operations in mathematical morphology, to construct a margin added
to the borders of predicted segmentation masks. At inference, the predicted set
formed by the mask and its margin contains the ground-truth mask with high
probability, at a confidence level specified by the user. The size of the
margin serves as an indicator of predictive uncertainty for a given model and
dataset. We work in a regime of minimal information as we do not require any
feedback from the predictor: only the predicted masks are needed for computing
the prediction sets. Hence, our method is applicable to any segmentation model,
including those based on deep learning; we evaluate our approach on several
medical imaging applications.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.05618v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/7/2025</p>
                </li>
                <li>
                    <h3>The shape of FIREbox galaxies and a potential tension with low-mass
  disks</h3>
                    <p><strong>Authors:</strong> Courtney Klein, James S. Bullock, Luke Xia, Jorge Moreno, Robert Feldmann, Francisco J. Mercado, Claude-André Faucher-Giguère, Jonathan Stern, N. Nicole Sanchez, Abdelaziz Hussein</p>
                    <p>  We study the intrinsic and observable shapes of approximately 700
star-forming galaxies with stellar masses $10^8 - 10^{11}$ M$_\odot$ from the
FIREbox simulation at $z=0$. We calculate intrinsic axis ratios using inertia
tensors weighted by: All Stars, Young Stars, and Luminosity-weighted Stars.
Young Stars, in particular, are arranged in systematically different 3D
configurations as a function of galaxy stellar mass, with spheroidal,
elongated, and disky shapes dominant at stellar masses of $10^{8.5}$ M$_\odot$,
$10^{9.5}$ M$_\odot$, and $10^{10.5}$ M$_\odot$, respectively. We construct
mock images for each galaxy and show that projected short-to-long axis ratios,
$q$, inferred from 2D S\'ersic fits are most closely related to
Luminosity-weighted tensor shapes and least resemble the All Stars shapes. This
suggests observed 2D shape distributions should not be compared to predictions
based on 3D stellar mass shapes. We construct a sample of mock images projected
in random orientations and compare them to observed axis ratio distributions
from the GAMA survey. For galaxies with stellar masses $10^{10} - 10^{11}$
M$_\odot$, we reproduce axis ratios comparable to the thinnest observed in real
galaxies ($q \sim 0.1$), suggesting this model is capable of making thin disk
galaxies at Milky Way scale. However, at masses below $10^{10}$ M$_\odot$, we
produce an insufficient population of galaxies with observed $q<0.4$ and none
with $q<0.2$, suggesting that FIREbox does not produce enough low-mass disk
galaxies. Future observational and theoretical programs aimed at understanding
low-mass disk fractions will provide crucial tests of galaxy formation models.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.05612v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/7/2025</p>
                </li>
                <li>
                    <h3>From Theory to Application: A Practical Introduction to Neural Operators
  in Scientific Computing</h3>
                    <p><strong>Authors:</strong> Prashant K. Jha</p>
                    <p>  This focused review explores a range of neural operator architectures for
approximating solutions to parametric partial differential equations (PDEs),
emphasizing high-level concepts and practical implementation strategies. The
study covers foundational models such as Deep Operator Networks (DeepONet),
Principal Component Analysis-based Neural Networks (PCANet), and Fourier Neural
Operators (FNO), providing comparative insights into their core methodologies
and performance. These architectures are demonstrated on two classical linear
parametric PDEs: the Poisson equation and linear elastic deformation. Beyond
forward problem-solving, the review delves into applying neural operators as
surrogates in Bayesian inference problems, showcasing their effectiveness in
accelerating posterior inference while maintaining accuracy. The paper
concludes by discussing current challenges, particularly in controlling
prediction accuracy and generalization. It outlines emerging strategies to
address these issues, such as residual-based error correction and multi-level
training. This review can be seen as a comprehensive guide to implementing
neural operators and integrating them into scientific computing workflows.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.05598v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/7/2025</p>
                </li>
                <li>
                    <h3>Search for primordial black holes from gravitational wave populations
  using deep learning</h3>
                    <p><strong>Authors:</strong> Hai-Long Huang, Jun-Qian Jiang, Jibin He, Yu-Tong Wang, Yun-Song Piao</p>
                    <p>  Gravitational waves (GWs) signals detected by the LIGO/Virgo/KAGRA
collaboration might be sourced (partly) by the merges of primordial black holes
(PBHs). The conventional hierarchical Bayesian inference methods can allow us
to study population properties of GW events to search for the hints for PBHs.
However, hierarchical Bayesian analysis require an analytic population model,
and becomes increasingly computationally expensive as the number of sources
grows. In this paper, we present a novel population analysis method based on
deep learning, which enables the direct and efficient estimation of PBH
population hyperparameters, such as the PBH fraction in dark matter, $f_{\rm
PBH}$. Our approach leverages neural posterior estimation combined with
conditional normalizing flows and two embedding networks. Our results
demonstrate that inference can be performed within seconds, highlighting the
promise of deep learning as a powerful tool for population inference with an
increasing number of GW signals for next-generation detectors.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.05570v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/7/2025</p>
                </li>
                <li>
                    <h3>Leveraging Approximate Caching for Faster Retrieval-Augmented Generation</h3>
                    <p><strong>Authors:</strong> Shai Bergman, Zhang Ji, Anne-Marie Kermarrec, Diana Petrescu, Rafael Pires, Mathis Randl, Martijn de Vos</p>
                    <p>  Retrieval-augmented generation (RAG) enhances the reliability of large
language model (LLM) answers by integrating external knowledge. However, RAG
increases the end-to-end inference time since looking for relevant documents
from large vector databases is computationally expensive. To address this, we
introduce Proximity, an approximate key-value cache that optimizes the RAG
workflow by leveraging similarities in user queries. Instead of treating each
query independently, Proximity reuses previously retrieved documents when
similar queries appear, reducing reliance on expensive vector database lookups.
We evaluate Proximity on the MMLU and MedRAG benchmarks, demonstrating that it
significantly improves retrieval efficiency while maintaining response
accuracy. Proximity reduces retrieval latency by up to 59% while maintaining
accuracy and lowers the computational burden on the vector database. We also
experiment with different similarity thresholds and quantify the trade-off
between speed and recall. Our work shows that approximate caching is a viable
and effective strategy for optimizing RAG-based systems.
</p>
                    <p><a href="http://arxiv.org/abs/2503.05530v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/7/2025</p>
                </li>
                <li>
                    <h3>A systemic and cybernetic perspective on causality, big data and social
  networks in tourism</h3>
                    <p><strong>Authors:</strong> Miguel Lloret-Climent, Andrés Montoyo-Guijarro, Yoan Gutierrez-Vázquez, Rafael Muñoz-Guillena, Kristian Alonso-Stenberg</p>
                    <p>  Purpose - The purpose of this paper is to propose a mathematical model to
determine invariant sets, set covering, orbits and, in particular, attractors
in the set of tourism variables. Analysis was carried out based on an algorithm
and applying an interpretation of chaos theory developed in the context of
General Systems Theory and Big Data. Design/methodology/approach - Tourism is
one of the most digitalized sectors of the economy, and social networks are an
important source of data for information gathering. However, the high levels of
redundant information on the Web and the appearance of contradictory opinions
and facts produce undesirable effects that must be cross-checked against real
data. This paper sets out the causal relationships associated with tourist
flows to enable the formulation of appropriate strategies. Findings - The
results can be applied to numerous cases, for example, in the analysis of
tourist flows, these findings can be used to determine whether the behaviour of
certain groups affects that of other groups, as well as analysing tourist
behaviour in terms of the most relevant variables. Originality/value - The
technique presented here breaks with the usual treatment of the tourism topics.
Unlike statistical analyses that merely provide information on current data,
the authors use orbit analysis to forecast, if attractors are found, the
behaviour of tourist variables in the immediate future.
</p>
                    <p><a href="http://arxiv.org/abs/2503.05502v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/7/2025</p>
                </li>
                <li>
                    <h3>Mol-CADiff: Causality-Aware Autoregressive Diffusion for Molecule
  Generation</h3>
                    <p><strong>Authors:</strong> Md Atik Ahamed, Qiang Ye, Qiang Cheng</p>
                    <p>  The design of novel molecules with desired properties is a key challenge in
drug discovery and materials science. Traditional methods rely on
trial-and-error, while recent deep learning approaches have accelerated
molecular generation. However, existing models struggle with generating
molecules based on specific textual descriptions. We introduce Mol-CADiff, a
novel diffusion-based framework that uses causal attention mechanisms for
text-conditional molecular generation. Our approach explicitly models the
causal relationship between textual prompts and molecular structures,
overcoming key limitations in existing methods. We enhance dependency modeling
both within and across modalities, enabling precise control over the generation
process. Our extensive experiments demonstrate that Mol-CADiff outperforms
state-of-the-art methods in generating diverse, novel, and chemically valid
molecules, with better alignment to specified properties, enabling more
intuitive language-driven molecular design.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.05499v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/7/2025</p>
                </li>
            </ul>
        </section>
    </main>
    <script src="scripts/papers.js"></script>
</body>
</html>