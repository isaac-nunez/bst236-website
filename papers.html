<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Papers</title>
    <link rel="stylesheet" href="styles/style.css">
</head>
<body>
    <div class="dog-container">
        <img src="images/dog.jpg" alt="My dog" class="dog-image">
        <p class="dog-caption">The guardian is observing</p>
    </div>
    <header>
        <h1>Papers</h1>
        <nav>
            <ul>
                <li><a href="main.html">Main (regular stuff)</a></li>
                <li><a href="games.html">Games (fun stuff)</a></li>
                <li><a href="papers.html">Papers (sciency stuff)</a></li>
                <li><a href="temperatures.html">Temperatures</a></li>
            </ul>
        </nav>
    </header>
    <main>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section id="papers-section">
            <h2>Latest Papers in Causal Inference</h2>
            <ul id="papersList">
                <li>
                    <h3>Enough Coin Flips Can Make LLMs Act Bayesian</h3>
                    <p><strong>Authors:</strong> Ritwik Gupta, Rodolfo Corona, Jiaxin Ge, Eric Wang, Dan Klein, Trevor Darrell, David M. Chan</p>
                    <p>  Large language models (LLMs) exhibit the ability to generalize given few-shot
examples in their input prompt, an emergent capability known as in-context
learning (ICL). We investigate whether LLMs utilize ICL to perform structured
reasoning in ways that are consistent with a Bayesian framework or rely on
pattern matching. Using a controlled setting of biased coin flips, we find
that: (1) LLMs often possess biased priors, causing initial divergence in
zero-shot settings, (2) in-context evidence outweighs explicit bias
instructions, (3) LLMs broadly follow Bayesian posterior updates, with
deviations primarily due to miscalibrated priors rather than flawed updates,
and (4) attention magnitude has negligible effect on Bayesian inference. With
sufficient demonstrations of biased coin flips via ICL, LLMs update their
priors in a Bayesian manner.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.04722v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/6/2025</p>
                </li>
                <li>
                    <h3>Floxels: Fast Unsupervised Voxel Based Scene Flow Estimation</h3>
                    <p><strong>Authors:</strong> David T. Hoffmann, Syed Haseeb Raza, Hanqiu Jiang, Denis Tananaev, Steffen Klingenhoefer, Martin Meinke</p>
                    <p>  Scene flow estimation is a foundational task for many robotic applications,
including robust dynamic object detection, automatic labeling, and sensor
synchronization. Two types of approaches to the problem have evolved: 1)
Supervised and 2) optimization-based methods. Supervised methods are fast
during inference and achieve high-quality results, however, they are limited by
the need for large amounts of labeled training data and are susceptible to
domain gaps. In contrast, unsupervised test-time optimization methods do not
face the problem of domain gaps but usually suffer from substantial runtime,
exhibit artifacts, or fail to converge to the right solution. In this work, we
mitigate several limitations of existing optimization-based methods. To this
end, we 1) introduce a simple voxel grid-based model that improves over the
standard MLP-based formulation in multiple dimensions and 2) introduce a new
multiframe loss formulation. 3) We combine both contributions in our new
method, termed Floxels. On the Argoverse 2 benchmark, Floxels is surpassed only
by EulerFlow among unsupervised methods while achieving comparable performance
at a fraction of the computational cost. Floxels achieves a massive speedup of
more than ~60 - 140x over EulerFlow, reducing the runtime from a day to 10
minutes per sequence. Over the faster but low-quality baseline, NSFP, Floxels
achieves a speedup of ~14x.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.04718v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/6/2025</p>
                </li>
                <li>
                    <h3>Inferring kilonova ejecta photospheric properties from early blackbody
  spectra</h3>
                    <p><strong>Authors:</strong> Gilad Sadeh</p>
                    <p>  We present simple analytic corrections to the standard blackbody fitting used
for early kilonova emission. We consider a spherical, relativistically
expanding shell that radiates thermally at a single temperature in its own rest
frame. Due to relativistic effects, including Doppler boosting, time delay, and
temperature evolution -- the observed temperature is smeared across different
polar angles by approximately $\sim10\%$. While the observed spectrum remains
roughly consistent with a single-temperature blackbody, neglecting relativistic
effects leads to significant systematic inaccuracies: the inferred photospheric
velocity and temperature are overestimated by up to $\sim50\%$ for mildly
relativistic velocities. By applying our analytic corrections, these deviations
are reduced to within $10\%$, even in cases where the photosphere is receding
and cooling is considered. Applying our corrections to observed kilonovae
(AT2017gfo and the thermal component of GRB211211A) reveals that standard
blackbody fitting overestimated the inferred velocities and temperatures by
$10\%-40\%$.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.04700v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/6/2025</p>
                </li>
                <li>
                    <h3>DEAL-YOLO: Drone-based Efficient Animal Localization using YOLO</h3>
                    <p><strong>Authors:</strong> Aditya Prashant Naidu, Hem Gosalia, Ishaan Gakhar, Shaurya Singh Rathore, Krish Didwania, Ujjwal Verma</p>
                    <p>  Although advances in deep learning and aerial surveillance technology are
improving wildlife conservation efforts, complex and erratic environmental
conditions still pose a problem, requiring innovative solutions for
cost-effective small animal detection. This work introduces DEAL-YOLO, a novel
approach that improves small object detection in Unmanned Aerial Vehicle (UAV)
images by using multi-objective loss functions like Wise IoU (WIoU) and
Normalized Wasserstein Distance (NWD), which prioritize pixels near the centre
of the bounding box, ensuring smoother localization and reducing abrupt
deviations. Additionally, the model is optimized through efficient feature
extraction with Linear Deformable (LD) convolutions, enhancing accuracy while
maintaining computational efficiency. The Scaled Sequence Feature Fusion (SSFF)
module enhances object detection by effectively capturing inter-scale
relationships, improving feature representation, and boosting metrics through
optimized multiscale fusion. Comparison with baseline models reveals high
efficacy with up to 69.5\% fewer parameters compared to vanilla Yolov8-N,
highlighting the robustness of the proposed modifications. Through this
approach, our paper aims to facilitate the detection of endangered species,
animal population analysis, habitat monitoring, biodiversity research, and
various other applications that enrich wildlife conservation efforts. DEAL-YOLO
employs a two-stage inference paradigm for object detection, refining selected
regions to improve localization and confidence. This approach enhances
performance, especially for small instances with low objectness scores.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.04698v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/6/2025</p>
                </li>
                <li>
                    <h3>Matrix Factorization for Inferring Associations and Missing Links</h3>
                    <p><strong>Authors:</strong> Ryan Barron, Maksim E. Eren, Duc P. Truong, Cynthia Matuszek, James Wendelberger, Mary F. Dorn, Boian Alexandrov</p>
                    <p>  Missing link prediction is a method for network analysis, with applications
in recommender systems, biology, social sciences, cybersecurity, information
retrieval, and Artificial Intelligence (AI) reasoning in Knowledge Graphs.
Missing link prediction identifies unseen but potentially existing connections
in a network by analyzing the observed patterns and relationships. In
proliferation detection, this supports efforts to identify and characterize
attempts by state and non-state actors to acquire nuclear weapons or associated
technology - a notoriously challenging but vital mission for global security.
Dimensionality reduction techniques like Non-Negative Matrix Factorization
(NMF) and Logistic Matrix Factorization (LMF) are effective but require
selection of the matrix rank parameter, that is, of the number of hidden
features, k, to avoid over/under-fitting. We introduce novel Weighted (WNMFk),
Boolean (BNMFk), and Recommender (RNMFk) matrix factorization methods, along
with ensemble variants incorporating logistic factorization, for link
prediction. Our methods integrate automatic model determination for rank
estimation by evaluating stability and accuracy using a modified bootstrap
methodology and uncertainty quantification (UQ), assessing prediction
reliability under random perturbations. We incorporate Otsu threshold selection
and k-means clustering for Boolean matrix factorization, comparing them to
coordinate descent-based Boolean thresholding. Our experiments highlight the
impact of rank k selection, evaluate model performance under varying test-set
sizes, and demonstrate the benefits of UQ for reliable predictions using
abstention. We validate our methods on three synthetic datasets (Boolean and
uniformly distributed) and benchmark them against LMF and symmetric LMF
(symLMF) on five real-world protein-protein interaction networks, showcasing an
improved prediction performance.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.04680v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/6/2025</p>
                </li>
                <li>
                    <h3>Multi-Agent Inverse Q-Learning from Demonstrations</h3>
                    <p><strong>Authors:</strong> Nathaniel Haynam, Adam Khoja, Dhruv Kumar, Vivek Myers, Erdem Bıyık</p>
                    <p>  When reward functions are hand-designed, deep reinforcement learning
algorithms often suffer from reward misspecification, causing them to learn
suboptimal policies in terms of the intended task objectives. In the
single-agent case, inverse reinforcement learning (IRL) techniques attempt to
address this issue by inferring the reward function from expert demonstrations.
However, in multi-agent problems, misalignment between the learned and true
objectives is exacerbated due to increased environment non-stationarity and
variance that scales with multiple agents. As such, in multi-agent general-sum
games, multi-agent IRL algorithms have difficulty balancing cooperative and
competitive objectives. To address these issues, we propose Multi-Agent
Marginal Q-Learning from Demonstrations (MAMQL), a novel sample-efficient
framework for multi-agent IRL. For each agent, MAMQL learns a critic
marginalized over the other agents' policies, allowing for a well-motivated use
of Boltzmann policies in the multi-agent context. We identify a connection
between optimal marginalized critics and single-agent soft-Q IRL, allowing us
to apply a direct, simple optimization criterion from the single-agent domain.
Across our experiments on three different simulated domains, MAMQL
significantly outperforms previous multi-agent methods in average reward,
sample efficiency, and reward recovery by often more than 2-5x. We make our
code available at https://sites.google.com/view/mamql .
</p>
                    <p><a href="http://arxiv.org/pdf/2503.04679v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/6/2025</p>
                </li>
                <li>
                    <h3>LLM-guided Plan and Retrieval: A Strategic Alignment for Interpretable
  User Satisfaction Estimation in Dialogue</h3>
                    <p><strong>Authors:</strong> Sangyeop Kim, Sohhyung Park, Jaewon Jung, Jinseok Kim, Sungzoon Cho</p>
                    <p>  Understanding user satisfaction with conversational systems, known as User
Satisfaction Estimation (USE), is essential for assessing dialogue quality and
enhancing user experiences. However, existing methods for USE face challenges
due to limited understanding of underlying reasons for user dissatisfaction and
the high costs of annotating user intentions. To address these challenges, we
propose PRAISE (Plan and Retrieval Alignment for Interpretable Satisfaction
Estimation), an interpretable framework for effective user satisfaction
prediction. PRAISE operates through three key modules. The Strategy Planner
develops strategies, which are natural language criteria for classifying user
satisfaction. The Feature Retriever then incorporates knowledge on user
satisfaction from Large Language Models (LLMs) and retrieves relevance features
from utterances. Finally, the Score Analyzer evaluates strategy predictions and
classifies user satisfaction. Experimental results demonstrate that PRAISE
achieves state-of-the-art performance on three benchmarks for the USE task.
Beyond its superior performance, PRAISE offers additional benefits. It enhances
interpretability by providing instance-level explanations through effective
alignment of utterances with strategies. Moreover, PRAISE operates more
efficiently than existing approaches by eliminating the need for LLMs during
the inference phase.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.04675v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/6/2025</p>
                </li>
                <li>
                    <h3>Joint Masked Reconstruction and Contrastive Learning for Mining
  Interactions Between Proteins</h3>
                    <p><strong>Authors:</strong> Jiang Li, Xiaoping Wang</p>
                    <p>  Protein-protein interaction (PPI) prediction is an instrumental means in
elucidating the mechanisms underlying cellular operations, holding significant
practical implications for the realms of pharmaceutical development and
clinical treatment. Presently, the majority of research methods primarily
concentrate on the analysis of amino acid sequences, while investigations
predicated on protein structures remain in the nascent stages of exploration.
Despite the emergence of several structure-based algorithms in recent years,
these are still confronted with inherent challenges: (1) the extraction of
intrinsic structural information of proteins typically necessitates the
expenditure of substantial computational resources; (2) these models are overly
reliant on seen protein data, struggling to effectively unearth interaction
cues between unknown proteins. To further propel advancements in this domain,
this paper introduces a novel PPI prediction method jointing masked
reconstruction and contrastive learning, termed JmcPPI. This methodology
dissects the PPI prediction task into two distinct phases: during the residue
structure encoding phase, JmcPPI devises two feature reconstruction tasks and
employs graph attention mechanism to capture structural information between
residues; during the protein interaction inference phase, JmcPPI perturbs the
original PPI graph and employs a multi-graph contrastive learning strategy to
thoroughly mine extrinsic interaction information of novel proteins. Extensive
experiments conducted on three widely utilized PPI datasets demonstrate that
JmcPPI surpasses existing optimal baseline models across various data partition
schemes. The associated code can be accessed via
https://github.com/lijfrank-open/JmcPPI.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.04650v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/6/2025</p>
                </li>
                <li>
                    <h3>Transferable Foundation Models for Geometric Tasks on Point Cloud
  Representations: Geometric Neural Operators</h3>
                    <p><strong>Authors:</strong> Blaine Quackenbush, Paul J. Atzberger</p>
                    <p>  We introduce methods for obtaining pretrained Geometric Neural Operators
(GNPs) that can serve as basal foundation models for use in obtaining geometric
features. These can be used within data processing pipelines for machine
learning tasks and numerical methods. We show how our GNPs can be trained to
learn robust latent representations for the differential geometry of
point-clouds to provide estimates of metric, curvature, and other shape-related
features. We demonstrate how our pre-trained GNPs can be used (i) to estimate
the geometric properties of surfaces of arbitrary shape and topologies with
robustness in the presence of noise, (ii) to approximate solutions of geometric
partial differential equations (PDEs) on manifolds, and (iii) to solve
equations for shape deformations such as curvature driven flows. We also
release a package of the codes and weights for using our pre-trained GNPs for
processing point cloud representations. This allows for incorporating our
pre-trained GNPs as components for reuse within existing and new data
processing pipelines. The GNPs also can be used as part of numerical solvers
involving geometry or as part of methods for performing inference and other
geometric tasks.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.04649v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/6/2025</p>
                </li>
                <li>
                    <h3>Assessing the performance of compartmental and renewal models for
  learning $R_{t}$ using spatially heterogeneous epidemic simulations on real
  geographies</h3>
                    <p><strong>Authors:</strong> Matthew Ghosh, Yunli Qi, Abbie Evans, Tom Reed, Lara Herriott, Ioana Bouros, Ben Lambert, David J. Gavaghan, Katherine M. Shepherd, Richard Creswell, Kit Gallagher</p>
                    <p>  The time-varying reproduction number ($R_t$) gives an indication of the
trajectory of an infectious disease outbreak. Commonly used frameworks for
inferring $R_t$ from epidemiological time series include those based on
compartmental models (such as the SEIR model) and renewal equation models.
These inference methods are usually validated using synthetic data generated
from a simple model, often from the same class of model as the inference
framework. However, in a real outbreak the transmission processes, and thus the
infection data collected, are much more complex. The performance of common
$R_t$ inference methods on data with similar complexity to real world scenarios
has been subject to less comprehensive validation. We therefore propose
evaluating these inference methods on outbreak data generated from a
sophisticated, geographically accurate agent-based model. We illustrate this
proposed method by generating synthetic data for two outbreaks in Northern
Ireland: one with minimal spatial heterogeneity, and one with additional
heterogeneity. We find that the simple SEIR model struggles with the greater
heterogeneity, while the renewal equation model demonstrates greater robustness
to spatial heterogeneity, though is sensitive to the accuracy of the generation
time distribution used in inference. Our approach represents a principled way
to benchmark epidemiological inference tools and is built upon an open-source
software platform for reproducible epidemic simulation and inference.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.04648v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/6/2025</p>
                </li>
            </ul>
        </section>
    </main>
    <script src="scripts/papers.js"></script>
</body>
</html>