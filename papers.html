<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Papers</title>
    <link rel="stylesheet" href="styles/style.css">
</head>
<body>
    <div class="dog-container">
        <img src="images/dog.jpg" alt="My dog" class="dog-image">
        <p class="dog-caption">The guardian is observing</p>
    </div>
    <header>
        <h1>Papers</h1>
        <nav>
            <ul>
                <li><a href="main.html">Main (regular stuff)</a></li>
                <li><a href="games.html">Games (fun stuff)</a></li>
                <li><a href="papers.html">Papers (sciency stuff)</a></li>
            </ul>
        </nav>
    </header>
    <main>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section id="papers-section">
            <h2>Latest Papers in Causal Inference</h2>
            <ul id="papersList">
                <li>
                    <h3>Fast Generation of Weak Lensing Maps in Modified Gravity with COLA</h3>
                    <p><strong>Authors:</strong> Sophie Hoyland, Hans A. Winther, Daniela Saadeh, Kazuya Koyama, Albert Izard</p>
                    <p>  Accurate predictions of weak lensing observables are essential for
understanding the large-scale structure of the Universe and probing the nature
of gravity. In this work, we present a lightcone implementation to generate
maps of the weak lensing convergence field using the COmoving Lagrangian
Acceleration (COLA) method. The lightcone is constructed in spherical shells
from the source to the observer following an onion representation of the
Universe.
  We validate the COLA-generated convergence maps in General Relativity by
comparing five statistics to those of maps obtained with the high-resolution
$N$-body simulations presented in Takahashi $et\ al.$ (2017): the power
spectrum, bispectrum, probability distribution function, peak counts and
Minkowski functionals. The convergence power spectrum is accurate to within
$5\%$ up to $\ell\sim500$ and to within $10\%$ up to $\ell\sim750$, confirming
the accuracy of this method on both linear and non-linear scales. For the
probability distribution function, peak counts and Minkowski functionals, we
determine the map pixel resolution required for COLA to capture the statistical
features of the $N$-body convergence maps.
  Our validation tests provide a baseline for the convergence map
specifications at which we can trust COLA for each statistic considered. Using
these map specifications, we extend our analyses to two representative theories
of Modified Gravity, and demonstrate their imprints on the five convergence
statistics considered. This work represents a step towards precise weak lensing
predictions under both General Relativity and Modified Gravity with reduced
computational cost, providing a robust framework to explore the nature of
gravity using field-level inference.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.14851v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/20/2025</p>
                </li>
                <li>
                    <h3>Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent
  Attention in Any Transformer-based LLMs</h3>
                    <p><strong>Authors:</strong> Tao Ji, Bin Guo, Yuanbin Wu, Qipeng Guo, Lixing Shen, Zhan Chen, Xipeng Qiu, Qi Zhang, Tao Gui</p>
                    <p>  Multi-head Latent Attention (MLA) is an innovative architecture proposed by
DeepSeek, designed to ensure efficient and economical inference by
significantly compressing the Key-Value (KV) cache into a latent vector.
Compared to MLA, standard LLMs employing Multi-Head Attention (MHA) and its
variants such as Grouped-Query Attention (GQA) exhibit significant cost
disadvantages. Enabling well-trained LLMs (e.g., Llama) to rapidly adapt to MLA
without pre-training from scratch is both meaningful and challenging. This
paper proposes the first data-efficient fine-tuning method for transitioning
from MHA to MLA (MHA2MLA), which includes two key components: for partial-RoPE,
we remove RoPE from dimensions of queries and keys that contribute less to the
attention scores, for low-rank approximation, we introduce joint SVD
approximations based on the pre-trained parameters of keys and values. These
carefully designed strategies enable MHA2MLA to recover performance using only
a small fraction (0.3% to 0.6%) of the data, significantly reducing inference
costs while seamlessly integrating with compression techniques such as KV cache
quantization. For example, the KV cache size of Llama2-7B is reduced by 92.19%,
with only a 0.5% drop in LongBench performance.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.14837v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/20/2025</p>
                </li>
                <li>
                    <h3>Fundamental Limitations in Defending LLM Finetuning APIs</h3>
                    <p><strong>Authors:</strong> Xander Davies, Eric Winsor, Tomek Korbak, Alexandra Souly, Robert Kirk, Christian Schroeder de Witt, Yarin Gal</p>
                    <p>  LLM developers have imposed technical interventions to prevent fine-tuning
misuse attacks, attacks where adversaries evade safeguards by fine-tuning the
model using a public API. Previous work has established several successful
attacks against specific fine-tuning API defences. In this work, we show that
defences of fine-tuning APIs that seek to detect individual harmful training or
inference samples ('pointwise' detection) are fundamentally limited in their
ability to prevent fine-tuning attacks. We construct 'pointwise-undetectable'
attacks that repurpose entropy in benign model outputs (e.g. semantic or
syntactic variations) to covertly transmit dangerous knowledge. Our attacks are
composed solely of unsuspicious benign samples that can be collected from the
model before fine-tuning, meaning training and inference samples are all
individually benign and low-perplexity. We test our attacks against the OpenAI
fine-tuning API, finding they succeed in eliciting answers to harmful
multiple-choice questions, and that they evade an enhanced monitoring system we
design that successfully detects other fine-tuning attacks. We encourage the
community to develop defences that tackle the fundamental limitations we
uncover in pointwise fine-tuning API defences.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.14828v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/20/2025</p>
                </li>
                <li>
                    <h3>Dynamic Low-Rank Sparse Adaptation for Large Language Models</h3>
                    <p><strong>Authors:</strong> Weizhong Huang, Yuxin Zhang, Xiawu Zheng, Yang Liu, Jing Lin, Yiwu Yao, Rongrong Ji</p>
                    <p>  Despite the efficacy of network sparsity in alleviating the deployment strain
of Large Language Models (LLMs), it endures significant performance
degradation. Applying Low-Rank Adaptation (LoRA) to fine-tune the sparse LLMs
offers an intuitive approach to counter this predicament, while it holds
shortcomings include: 1) The inability to integrate LoRA weights into sparse
LLMs post-training, and 2) Insufficient performance recovery at high sparsity
ratios. In this paper, we introduce dynamic Low-rank Sparse Adaptation (LoSA),
a novel method that seamlessly integrates low-rank adaptation into LLM sparsity
within a unified framework, thereby enhancing the performance of sparse LLMs
without increasing the inference latency. In particular, LoSA dynamically
sparsifies the LoRA outcomes based on the corresponding sparse weights during
fine-tuning, thus guaranteeing that the LoRA module can be integrated into the
sparse LLMs post-training. Besides, LoSA leverages Representation Mutual
Information (RMI) as an indicator to determine the importance of layers,
thereby efficiently determining the layer-wise sparsity rates during
fine-tuning. Predicated on this, LoSA adjusts the rank of the LoRA module based
on the variability in layer-wise reconstruction errors, allocating an
appropriate fine-tuning for each layer to reduce the output discrepancies
between dense and sparse LLMs. Extensive experiments tell that LoSA can
efficiently boost the efficacy of sparse LLMs within a few hours, without
introducing any additional inferential burden. For example, LoSA reduced the
perplexity of sparse LLaMA-2-7B by 68.73 and increased zero-shot accuracy by
16.32$\%$, achieving a 2.60$\times$ speedup on CPU and 2.23$\times$ speedup on
GPU, requiring only 45 minutes of fine-tuning on a single NVIDIA A100 80GB GPU.
Code is available at https://github.com/wzhuang-xmu/LoSA.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.14816v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/20/2025</p>
                </li>
                <li>
                    <h3>Ray-Tracing for Conditionally Activated Neural Networks</h3>
                    <p><strong>Authors:</strong> Claudio Gallicchio, Giuseppe Nuti</p>
                    <p>  In this paper, we introduce a novel architecture for conditionally activated
neural networks combining a hierarchical construction of multiple Mixture of
Experts (MoEs) layers with a sampling mechanism that progressively converges to
an optimized configuration of expert activation. This methodology enables the
dynamic unfolding of the network's architecture, facilitating efficient
path-specific training. Experimental results demonstrate that this approach
achieves competitive accuracy compared to conventional baselines while
significantly reducing the parameter count required for inference. Notably,
this parameter reduction correlates with the complexity of the input patterns,
a property naturally emerging from the network's operational dynamics without
necessitating explicit auxiliary penalty functions.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.14788v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/20/2025</p>
                </li>
                <li>
                    <h3>SigLIP 2: Multilingual Vision-Language Encoders with Improved Semantic
  Understanding, Localization, and Dense Features</h3>
                    <p><strong>Authors:</strong> Michael Tschannen, Alexey Gritsenko, Xiao Wang, Muhammad Ferjad Naeem, Ibrahim Alabdulmohsin, Nikhil Parthasarathy, Talfan Evans, Lucas Beyer, Ye Xia, Basil Mustafa, Olivier Hénaff, Jeremiah Harmsen, Andreas Steiner, Xiaohua Zhai</p>
                    <p>  We introduce SigLIP 2, a family of new multilingual vision-language encoders
that build on the success of the original SigLIP. In this second iteration, we
extend the original image-text training objective with several prior,
independently developed techniques into a unified recipe -- this includes
captioning-based pretraining, self-supervised losses (self-distillation, masked
prediction) and online data curation. With these changes, SigLIP 2 models
outperform their SigLIP counterparts at all model scales in core capabilities,
including zero-shot classification, image-text retrieval, and transfer
performance when extracting visual representations for Vision-Language Models
(VLMs). Furthermore, the new training recipe leads to significant improvements
on localization and dense prediction tasks. We also train variants which
support multiple resolutions and preserve the input's native aspect ratio.
Finally, we train on a more diverse data-mixture that includes de-biasing
techniques, leading to much better multilingual understanding and improved
fairness. To allow users to trade off inference cost with performance, we
release model checkpoints at four sizes: ViT-B (86M), L (303M), So400m (400M),
and g (1B).
</p>
                    <p><a href="http://arxiv.org/pdf/2502.14786v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/20/2025</p>
                </li>
                <li>
                    <h3>Efficient Multivariate Robust Mean Estimation Under Mean-Shift
  Contamination</h3>
                    <p><strong>Authors:</strong> Ilias Diakonikolas, Giannis Iakovidis, Daniel M. Kane, Thanasis Pittas</p>
                    <p>  We study the algorithmic problem of robust mean estimation of an identity
covariance Gaussian in the presence of mean-shift contamination. In this
contamination model, we are given a set of points in $\mathbb{R}^d$ generated
i.i.d. via the following process. For a parameter $\alpha<1/2$, the $i$-th
sample $x_i$ is obtained as follows: with probability $1-\alpha$, $x_i$ is
drawn from $\mathcal{N}(\mu, I)$, where $\mu \in \mathbb{R}^d$ is the target
mean; and with probability $\alpha$, $x_i$ is drawn from $\mathcal{N}(z_i, I)$,
where $z_i$ is unknown and potentially arbitrary. Prior work characterized the
information-theoretic limits of this task. Specifically, it was shown that, in
contrast to Huber contamination, in the presence of mean-shift contamination
consistent estimation is possible. On the other hand, all known robust
estimators in the mean-shift model have running times exponential in the
dimension. Here we give the first computationally efficient algorithm for
high-dimensional robust mean estimation with mean-shift contamination that can
tolerate a constant fraction of outliers. In particular, our algorithm has
near-optimal sample complexity, runs in sample-polynomial time, and
approximates the target mean to any desired accuracy. Conceptually, our result
contributes to a growing body of work that studies inference with respect to
natural noise models lying in between fully adversarial and random settings.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.14772v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/20/2025</p>
                </li>
                <li>
                    <h3>Step-by-Step Fact Verification System for Medical Claims with
  Explainable Reasoning</h3>
                    <p><strong>Authors:</strong> Juraj Vladika, Ivana Hacajová, Florian Matthes</p>
                    <p>  Fact verification (FV) aims to assess the veracity of a claim based on
relevant evidence. The traditional approach for automated FV includes a
three-part pipeline relying on short evidence snippets and encoder-only
inference models. More recent approaches leverage the multi-turn nature of LLMs
to address FV as a step-by-step problem where questions inquiring additional
context are generated and answered until there is enough information to make a
decision. This iterative method makes the verification process rational and
explainable. While these methods have been tested for encyclopedic claims,
exploration on domain-specific and realistic claims is missing. In this work,
we apply an iterative FV system on three medical fact-checking datasets and
evaluate it with multiple settings, including different LLMs, external web
search, and structured reasoning using logic predicates. We demonstrate
improvements in the final performance over traditional approaches and the high
potential of step-by-step FV systems for domain-specific claims.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.14765v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/20/2025</p>
                </li>
                <li>
                    <h3>Sculpting [CLS] Features for Pre-Trained Model-Based Class-Incremental
  Learning</h3>
                    <p><strong>Authors:</strong> Murat Onur Yildirim, Elif Ceren Gok Yildirim, Joaquin Vanschoren</p>
                    <p>  Class-incremental learning requires models to continually acquire knowledge
of new classes without forgetting old ones. Although pre-trained models have
demonstrated strong performance in class-incremental learning, they remain
susceptible to catastrophic forgetting when learning new concepts. Excessive
plasticity in the models breaks generalizability and causes forgetting, while
strong stability results in insufficient adaptation to new classes. This
necessitates effective adaptation with minimal modifications to preserve the
general knowledge of pre-trained models. To address this challenge, we first
introduce a new parameter-efficient fine-tuning module 'Learn and Calibrate',
or LuCA, designed to acquire knowledge through an adapter-calibrator couple,
enabling effective adaptation with well-refined feature representations.
Second, for each learning session, we deploy a sparse LuCA module on top of the
last token just before the classifier, which we refer to as 'Token-level Sparse
Calibration and Adaptation', or TOSCA. This strategic design improves the
orthogonality between the modules and significantly reduces both training and
inference complexity. By leaving the generalization capabilities of the
pre-trained models intact and adapting exclusively via the last token, our
approach achieves a harmonious balance between stability and plasticity.
Extensive experiments demonstrate TOSCA's state-of-the-art performance while
introducing ~8 times fewer parameters compared to prior methods.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.14762v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/20/2025</p>
                </li>
                <li>
                    <h3>Multi-Objective Causal Bayesian Optimization</h3>
                    <p><strong>Authors:</strong> Shriya Bhatija, Paul-David Zuercher, Jakob Thumm, Thomas Bohné</p>
                    <p>  In decision-making problems, the outcome of an intervention often depends on
the causal relationships between system components and is highly costly to
evaluate. In such settings, causal Bayesian optimization (CBO) can exploit the
causal relationships between the system variables and sequentially perform
interventions to approach the optimum with minimal data. Extending CBO to the
multi-outcome setting, we propose Multi-Objective Causal Bayesian Optimization
(MO-CBO), a paradigm for identifying Pareto-optimal interventions within a
known multi-target causal graph. We first derive a graphical characterization
for potentially optimal sets of variables to intervene upon. Showing that any
MO-CBO problem can be decomposed into several traditional multi-objective
optimization tasks, we then introduce an algorithm that sequentially balances
exploration across these tasks using relative hypervolume improvement. The
proposed method will be validated on both synthetic and real-world causal
graphs, demonstrating its superiority over traditional (non-causal)
multi-objective Bayesian optimization in settings where causal information is
available.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.14755v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/20/2025</p>
                </li>
            </ul>
        </section>
    </main>
    <script src="scripts/papers.js"></script>
</body>
</html>