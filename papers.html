<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Papers</title>
    <link rel="stylesheet" href="styles/style.css">
</head>
<body>
    <div class="dog-container">
        <img src="images/dog.jpg" alt="My dog" class="dog-image">
        <p class="dog-caption">The guardian is observing</p>
    </div>
    <header>
        <h1>Papers</h1>
        <nav>
            <ul>
                <li><a href="main.html">Main (regular stuff)</a></li>
                <li><a href="games.html">Games (fun stuff)</a></li>
                <li><a href="papers.html">Papers (sciency stuff)</a></li>
                <li><a href="temperatures.html">Temperatures</a></li>
            </ul>
        </nav>
    </header>
    <main>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section id="papers-section">
            <h2>Latest Papers in Causal Inference</h2>
            <ul id="papersList">
                <li>
                    <h3>Gaussian Mixture Flow Matching Models</h3>
                    <p><strong>Authors:</strong> Hansheng Chen, Kai Zhang, Hao Tan, Zexiang Xu, Fujun Luan, Leonidas Guibas, Gordon Wetzstein, Sai Bi</p>
                    <p>  Diffusion models approximate the denoising distribution as a Gaussian and
predict its mean, whereas flow matching models reparameterize the Gaussian mean
as flow velocity. However, they underperform in few-step sampling due to
discretization error and tend to produce over-saturated colors under
classifier-free guidance (CFG). To address these limitations, we propose a
novel Gaussian mixture flow matching (GMFlow) model: instead of predicting the
mean, GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a
multi-modal flow velocity distribution, which can be learned with a KL
divergence loss. We demonstrate that GMFlow generalizes previous diffusion and
flow matching models where a single Gaussian is learned with an $L_2$ denoising
loss. For inference, we derive GM-SDE/ODE solvers that leverage analytic
denoising distributions and velocity fields for precise few-step sampling.
Furthermore, we introduce a novel probabilistic guidance scheme that mitigates
the over-saturation issues of CFG and improves image generation quality.
Extensive experiments demonstrate that GMFlow consistently outperforms flow
matching baselines in generation quality, achieving a Precision of 0.942 with
only 6 sampling steps on ImageNet 256$\times$256.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.05304v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 4/7/2025</p>
                </li>
                <li>
                    <h3>InteractVLM: 3D Interaction Reasoning from 2D Foundational Models</h3>
                    <p><strong>Authors:</strong> Sai Kumar Dwivedi, Dimitrije Antić, Shashank Tripathi, Omid Taheri, Cordelia Schmid, Michael J. Black, Dimitrios Tzionas</p>
                    <p>  We introduce InteractVLM, a novel method to estimate 3D contact points on
human bodies and objects from single in-the-wild images, enabling accurate
human-object joint reconstruction in 3D. This is challenging due to occlusions,
depth ambiguities, and widely varying object shapes. Existing methods rely on
3D contact annotations collected via expensive motion-capture systems or
tedious manual labeling, limiting scalability and generalization. To overcome
this, InteractVLM harnesses the broad visual knowledge of large Vision-Language
Models (VLMs), fine-tuned with limited 3D contact data. However, directly
applying these models is non-trivial, as they reason only in 2D, while
human-object contact is inherently 3D. Thus we introduce a novel
Render-Localize-Lift module that: (1) embeds 3D body and object surfaces in 2D
space via multi-view rendering, (2) trains a novel multi-view localization
model (MV-Loc) to infer contacts in 2D, and (3) lifts these to 3D.
Additionally, we propose a new task called Semantic Human Contact estimation,
where human contact predictions are conditioned explicitly on object semantics,
enabling richer interaction modeling. InteractVLM outperforms existing work on
contact estimation and also facilitates 3D reconstruction from an in-the wild
image. Code and models are available at https://interactvlm.is.tue.mpg.de.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.05303v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 4/7/2025</p>
                </li>
                <li>
                    <h3>SmolVLM: Redefining small and efficient multimodal models</h3>
                    <p><strong>Authors:</strong> Andrés Marafioti, Orr Zohar, Miquel Farré, Merve Noyan, Elie Bakouch, Pedro Cuenca, Cyril Zakka, Loubna Ben Allal, Anton Lozhkov, Nouamane Tazi, Vaibhav Srivastav, Joshua Lochner, Hugo Larcher, Mathieu Morlon, Lewis Tunstall, Leandro von Werra, Thomas Wolf</p>
                    <p>  Large Vision-Language Models (VLMs) deliver exceptional performance but
require significant computational resources, limiting their deployment on
mobile and edge devices. Smaller VLMs typically mirror design choices of larger
models, such as extensive image tokenization, leading to inefficient GPU memory
usage and constrained practicality for on-device applications.
  We introduce SmolVLM, a series of compact multimodal models specifically
engineered for resource-efficient inference. We systematically explore
architectural configurations, tokenization strategies, and data curation
optimized for low computational overhead. Through this, we identify key design
choices that yield substantial performance gains on image and video tasks with
minimal memory footprints.
  Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during
inference and outperforms the 300-times larger Idefics-80B model, despite an
18-month development gap. Our largest model, at 2.2B parameters, rivals
state-of-the-art VLMs consuming twice the GPU memory. SmolVLM models extend
beyond static images, demonstrating robust video comprehension capabilities.
  Our results emphasize that strategic architectural optimizations, aggressive
yet efficient tokenization, and carefully curated training data significantly
enhance multimodal performance, facilitating practical, energy-efficient
deployments at significantly smaller scales.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.05299v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 4/7/2025</p>
                </li>
                <li>
                    <h3>Truthful or Fabricated? Using Causal Attribution to Mitigate Reward
  Hacking in Explanations</h3>
                    <p><strong>Authors:</strong> Pedro Ferreira, Wilker Aziz, Ivan Titov</p>
                    <p>  Chain-of-thought explanations are widely used to inspect the decision process
of large language models (LLMs) and to evaluate the trustworthiness of model
outputs, making them important for effective collaboration between LLMs and
humans. We demonstrate that preference optimization - a key step in the
alignment phase - can inadvertently reduce the faithfulness of these
explanations. This occurs because the reward model (RM), which guides
alignment, is tasked with optimizing both the expected quality of the response
and the appropriateness of the explanations (e.g., minimizing bias or adhering
to safety standards), creating potential conflicts. The RM lacks a mechanism to
assess the consistency between the model's internal decision process and the
generated explanation. Consequently, the LLM may engage in "reward hacking" by
producing a final response that scores highly while giving an explanation
tailored to maximize reward rather than accurately reflecting its reasoning. To
address this issue, we propose enriching the RM's input with a causal
attribution of the prediction, allowing the RM to detect discrepancies between
the generated self-explanation and the model's decision process. In controlled
settings, we show that this approach reduces the tendency of the LLM to
generate misleading explanations.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.05294v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 4/7/2025</p>
                </li>
                <li>
                    <h3>The challenge of uncertainty quantification of large language models in
  medicine</h3>
                    <p><strong>Authors:</strong> Zahra Atf, Seyed Amir Ahmad Safavi-Naini, Peter R. Lewis, Aref Mahjoubfar, Nariman Naderi, Thomas R. Savage, Ali Soroush</p>
                    <p>  This study investigates uncertainty quantification in large language models
(LLMs) for medical applications, emphasizing both technical innovations and
philosophical implications. As LLMs become integral to clinical
decision-making, accurately communicating uncertainty is crucial for ensuring
reliable, safe, and ethical AI-assisted healthcare. Our research frames
uncertainty not as a barrier but as an essential part of knowledge that invites
a dynamic and reflective approach to AI design. By integrating advanced
probabilistic methods such as Bayesian inference, deep ensembles, and Monte
Carlo dropout with linguistic analysis that computes predictive and semantic
entropy, we propose a comprehensive framework that manages both epistemic and
aleatoric uncertainties. The framework incorporates surrogate modeling to
address limitations of proprietary APIs, multi-source data integration for
better context, and dynamic calibration via continual and meta-learning.
Explainability is embedded through uncertainty maps and confidence metrics to
support user trust and clinical interpretability. Our approach supports
transparent and ethical decision-making aligned with Responsible and Reflective
AI principles. Philosophically, we advocate accepting controlled ambiguity
instead of striving for absolute predictability, recognizing the inherent
provisionality of medical knowledge.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.05278v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 4/7/2025</p>
                </li>
                <li>
                    <h3>AnomalousNet: A Hybrid Approach with Attention U-Nets and Change Point
  Detection for Accurate Characterization of Anomalous Diffusion in Video Data</h3>
                    <p><strong>Authors:</strong> Yusef Ahsini, Marc Escoto, J. Alberto Conejero</p>
                    <p>  Anomalous diffusion occurs in a wide range of systems, including protein
transport within cells, animal movement in complex habitats, pollutant
dispersion in groundwater, and nanoparticle motion in synthetic materials.
Accurately estimating the anomalous diffusion exponent and the diffusion
coefficient from the particle trajectories is essential to distinguish between
sub-diffusive, super-diffusive, or normal diffusion regimes. These estimates
provide a deeper insight into the underlying dynamics of the system,
facilitating the identification of particle behaviors and the detection of
changes in diffusion states. However, analyzing short and noisy video data,
which often yield incomplete and heterogeneous trajectories, poses a
significant challenge for traditional statistical approaches. We introduce a
data-driven method that integrates particle tracking, an attention
  U-Net architecture, and a change-point detection algorithm to address these
issues. This approach not only infers the anomalous diffusion parameters with
high accuracy but also identifies temporal transitions between different
states, even in the presence of noise and limited temporal resolution. Our
methodology demonstrated strong performance in the 2nd Anomalous Diffusion
(AnDi) Challenge benchmark within the top submissions for video tasks.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.05271v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 4/7/2025</p>
                </li>
                <li>
                    <h3>Learning to Reason Over Time: Timeline Self-Reflection for Improved
  Temporal Reasoning in Language Models</h3>
                    <p><strong>Authors:</strong> Adrián Bazaga, Rexhina Blloshmi, Bill Byrne, Adrià de Gispert</p>
                    <p>  Large Language Models (LLMs) have emerged as powerful tools for generating
coherent text, understanding context, and performing reasoning tasks. However,
they struggle with temporal reasoning, which requires processing time-related
information such as event sequencing, durations, and inter-temporal
relationships. These capabilities are critical for applications including
question answering, scheduling, and historical analysis. In this paper, we
introduce TISER, a novel framework that enhances the temporal reasoning
abilities of LLMs through a multi-stage process that combines timeline
construction with iterative self-reflection. Our approach leverages test-time
scaling to extend the length of reasoning traces, enabling models to capture
complex temporal dependencies more effectively. This strategy not only boosts
reasoning accuracy but also improves the traceability of the inference process.
Experimental results demonstrate state-of-the-art performance across multiple
benchmarks, including out-of-distribution test sets, and reveal that TISER
enables smaller open-source models to surpass larger closed-weight models on
challenging temporal reasoning tasks.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.05258v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 4/7/2025</p>
                </li>
                <li>
                    <h3>PINNverse: Accurate parameter estimation in differential equations from
  noisy data with constrained physics-informed neural networks</h3>
                    <p><strong>Authors:</strong> Marius Almanstötter, Roman Vetter, Dagmar Iber</p>
                    <p>  Parameter estimation for differential equations from measured data is an
inverse problem prevalent across quantitative sciences. Physics-Informed Neural
Networks (PINNs) have emerged as effective tools for solving such problems,
especially with sparse measurements and incomplete system information. However,
PINNs face convergence issues, stability problems, overfitting, and complex
loss function design. Here we introduce PINNverse, a training paradigm that
addresses these limitations by reformulating the learning process as a
constrained differential optimization problem. This approach achieves a dynamic
balance between data loss and differential equation residual loss during
training while preventing overfitting. PINNverse combines the advantages of
PINNs with the Modified Differential Method of Multipliers to enable
convergence on any point on the Pareto front. We demonstrate robust and
accurate parameter estimation from noisy data in four classical ODE and PDE
models from physics and biology. Our method enables accurate parameter
inference also when the forward problem is expensive to solve.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.05248v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 4/7/2025</p>
                </li>
                <li>
                    <h3>Behind the Spotlight: A systematic assessment of outshining using NIRCam
  medium-bands in the JADES Origins Field</h3>
                    <p><strong>Authors:</strong> Thomas Harvey, Christopher J. Conselice, Nathan J. Adams, Duncan Austin, Qiong Li, Vadim Rusakov, Lewi Westcott, Caio M. Goolsby, Christopher C. Lovell, Rachel K. Cochrane, Aswin P. Vijayan, James Trussler</p>
                    <p>  The spatial resolution and sensitivity of JWST's NIRCam instrument has
revolutionised our ability to probe the internal structure of early galaxies.
By leveraging deep medium-band imaging in the Jades Origins Field, we assemble
comprehensive spectral energy distributions (SEDs) using 19 photometric bands
for over 200 high-redshift galaxies ($z \geq 4.5$). We present an analysis of
this sample with particular emphasis on investigating the "outshining"
phenomenon, which can bias the inferred stellar populations by masking the
presence of evolved stellar populations ($\geq$ 100 Myr) with the light of
bright, young O and B-type stars. We address this problem by performing
spatially-resolved SED-fitting of both binned and full pixel-by-pixel
photometry, which we compare to the traditional integrated approach. We find
evidence for systematic underestimation of stellar mass in low-mass galaxies
($\leq 10^9 \rm M_\odot$) with bursty star formation, which can exceed a factor
of 10 in individual cases, but on average is typically a factor of 1.25-2.5,
depending on the binning methodology and SFH model used. The observed mass
offset correlates with burstiness (SFR$_{10 \ \rm Myr}$/SFR$_{100 \ \rm Myr}$)
and sSFR, such that galaxies with recently rising SFHs have larger mass
offsets. The integrated SFH models which produce the most consistent stellar
masses are the double power-law and non-parametric `continuity' models,
although no integrated model fully reproduces all resolved SFHs. We apply an
outshining correction factor to the Stellar Mass Function at $z=7$, finding
little impact within the uncertainties. We conclude that outshining can be
important in individual low-mass galaxies, but the overall impact is limited
and should be considered alongside other systematic SED fitting effects.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.05244v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 4/7/2025</p>
                </li>
                <li>
                    <h3>Bayesian local clustering of age-period mortality surfaces across
  multiple countries</h3>
                    <p><strong>Authors:</strong> Giovanni Romanò, Emanuele Aliverti, Daniele Durante</p>
                    <p>  Although traditional literature on mortality modeling has focused on single
countries in isolation, recent contributions have progressively moved toward
joint models for multiple countries. Besides favoring borrowing of information
to improve age-period forecasts, this perspective has also potentials to infer
local similarities among countries' mortality patterns in specific age classes
and periods that could unveil unexplored demographic trends, while guiding the
design of targeted policies. Advancements along this latter relevant direction
are currently undermined by the lack of a multi-country model capable of
incorporating the core structures of age-period mortality surfaces together
with clustering patterns among countries that are not global, but rather vary
locally across different combinations of ages and periods. We cover this gap by
developing a novel Bayesian model for log-mortality rates that characterizes
the age structure of mortality through a B-spline expansion whose
country-specific dynamic coefficients encode both changes of this age structure
across periods and also local clustering patterns among countries under a
time-dependent random partition prior for these country-specific dynamic
coefficients. While flexible, this formulation admits tractable posterior
inference leveraging a suitably-designed Gibbs-sampler. The application to
mortality data from 14 countries unveils local similarities highlighting both
previously-recognized demographic phenomena and also yet-unexplored trends.
</p>
                    <p><a href="http://arxiv.org/pdf/2504.05240v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 4/7/2025</p>
                </li>
            </ul>
        </section>
    </main>
    <script src="scripts/papers.js"></script>
</body>
</html>