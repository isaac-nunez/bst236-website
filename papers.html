<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Papers</title>
    <link rel="stylesheet" href="styles/style.css">
</head>
<body>
    <div class="dog-container">
        <img src="images/dog.jpg" alt="My dog" class="dog-image">
        <p class="dog-caption">The guardian is observing</p>
    </div>
    <header>
        <h1>Papers</h1>
        <nav>
            <ul>
                <li><a href="main.html">Main (regular stuff)</a></li>
                <li><a href="games.html">Games (fun stuff)</a></li>
                <li><a href="papers.html">Papers (sciency stuff)</a></li>
            </ul>
        </nav>
    </header>
    <main>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section id="papers-section">
            <h2>Latest Papers in Causal Inference</h2>
            <ul id="papersList">
                <li>
                    <h3>Diffusion Models without Classifier-free Guidance</h3>
                    <p><strong>Authors:</strong> Zhicong Tang, Jianmin Bao, Dong Chen, Baining Guo</p>
                    <p>  This paper presents Model-guidance (MG), a novel objective for training
diffusion model that addresses and removes of the commonly used Classifier-free
guidance (CFG). Our innovative approach transcends the standard modeling of
solely data distribution to incorporating the posterior probability of
conditions. The proposed technique originates from the idea of CFG and is easy
yet effective, making it a plug-and-play module for existing models. Our method
significantly accelerates the training process, doubles the inference speed,
and achieve exceptional quality that parallel and even surpass concurrent
diffusion models with CFG. Extensive experiments demonstrate the effectiveness,
efficiency, scalability on different models and datasets. Finally, we establish
state-of-the-art performance on ImageNet 256 benchmarks with an FID of 1.34.
Our code is available at https://github.com/tzco/Diffusion-wo-CFG.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12154v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/17/2025</p>
                </li>
                <li>
                    <h3>Idiosyncrasies in Large Language Models</h3>
                    <p><strong>Authors:</strong> Mingjie Sun, Yida Yin, Zhiqiu Xu, J. Zico Kolter, Zhuang Liu</p>
                    <p>  In this work, we unveil and study idiosyncrasies in Large Language Models
(LLMs) -- unique patterns in their outputs that can be used to distinguish the
models. To do so, we consider a simple classification task: given a particular
text output, the objective is to predict the source LLM that generates the
text. We evaluate this synthetic task across various groups of LLMs and find
that simply fine-tuning existing text embedding models on LLM-generated texts
yields excellent classification accuracy. Notably, we achieve 97.1% accuracy on
held-out validation data in the five-way classification problem involving
ChatGPT, Claude, Grok, Gemini, and DeepSeek. Our further investigation reveals
that these idiosyncrasies are rooted in word-level distributions. These
patterns persist even when the texts are rewritten, translated, or summarized
by an external LLM, suggesting that they are also encoded in the semantic
content. Additionally, we leverage LLM as judges to generate detailed,
open-ended descriptions of each model's idiosyncrasies. Finally, we discuss the
broader implications of our findings, particularly for training on synthetic
data and inferring model similarity. Code is available at
https://github.com/locuslab/llm-idiosyncrasies.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12150v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/17/2025</p>
                </li>
                <li>
                    <h3>Diffusion-Sharpening: Fine-tuning Diffusion Models with Denoising
  Trajectory Sharpening</h3>
                    <p><strong>Authors:</strong> Ye Tian, Ling Yang, Xinchen Zhang, Yunhai Tong, Mengdi Wang, Bin Cui</p>
                    <p>  We propose Diffusion-Sharpening, a fine-tuning approach that enhances
downstream alignment by optimizing sampling trajectories. Existing RL-based
fine-tuning methods focus on single training timesteps and neglect
trajectory-level alignment, while recent sampling trajectory optimization
methods incur significant inference NFE costs. Diffusion-Sharpening overcomes
this by using a path integral framework to select optimal trajectories during
training, leveraging reward feedback, and amortizing inference costs. Our
method demonstrates superior training efficiency with faster convergence, and
best inference efficiency without requiring additional NFEs. Extensive
experiments show that Diffusion-Sharpening outperforms RL-based fine-tuning
methods (e.g., Diffusion-DPO) and sampling trajectory optimization methods
(e.g., Inference Scaling) across diverse metrics including text alignment,
compositional capabilities, and human preferences, offering a scalable and
efficient solution for future diffusion model fine-tuning. Code:
https://github.com/Gen-Verse/Diffusion-Sharpening
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12146v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/17/2025</p>
                </li>
                <li>
                    <h3>FLARE: Feed-forward Geometry, Appearance and Camera Estimation from
  Uncalibrated Sparse Views</h3>
                    <p><strong>Authors:</strong> Shangzhan Zhang, Jianyuan Wang, Yinghao Xu, Nan Xue, Christian Rupprecht, Xiaowei Zhou, Yujun Shen, Gordon Wetzstein</p>
                    <p>  We present FLARE, a feed-forward model designed to infer high-quality camera
poses and 3D geometry from uncalibrated sparse-view images (i.e., as few as 2-8
inputs), which is a challenging yet practical setting in real-world
applications. Our solution features a cascaded learning paradigm with camera
pose serving as the critical bridge, recognizing its essential role in mapping
3D structures onto 2D image planes. Concretely, FLARE starts with camera pose
estimation, whose results condition the subsequent learning of geometric
structure and appearance, optimized through the objectives of geometry
reconstruction and novel-view synthesis. Utilizing large-scale public datasets
for training, our method delivers state-of-the-art performance in the tasks of
pose estimation, geometry reconstruction, and novel view synthesis, while
maintaining the inference efficiency (i.e., less than 0.5 seconds). The project
page and code can be found at: https://zhanghe3z.github.io/FLARE/
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12138v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/17/2025</p>
                </li>
                <li>
                    <h3>On the Query Complexity of Verifier-Assisted Language Generation</h3>
                    <p><strong>Authors:</strong> Edoardo Botta, Yuchen Li, Aashay Mehta, Jordan T. Ash, Cyril Zhang, Andrej Risteski</p>
                    <p>  Recently, a plethora of works have proposed inference-time algorithms (e.g.
best-of-n), which incorporate verifiers to assist the generation process. Their
quality-efficiency trade-offs have been empirically benchmarked on a variety of
constrained generation tasks, but the algorithmic design landscape is still
largely poorly understood. In this paper, we develop a mathematical framework
for reasoning about constrained generation using a pre-trained language model
generator oracle and a process verifier--which can decide whether a prefix can
be extended to a string which satisfies the constraints of choice. We show that
even in very simple settings, access to a verifier can render an intractable
problem (information-theoretically or computationally) to a tractable one. In
fact, we show even simple algorithms, like tokenwise rejection sampling, can
enjoy significant benefits from access to a verifier. Empirically, we show that
a natural modification of tokenwise rejection sampling, in which the sampler is
allowed to "backtrack" (i.e., erase the final few generated tokens) has robust
and substantive benefits over natural baselines (e.g. (blockwise) rejection
sampling, nucleus sampling)--both in terms of computational efficiency,
accuracy and diversity.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12123v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/17/2025</p>
                </li>
                <li>
                    <h3>PRISM: Self-Pruning Intrinsic Selection Method for Training-Free
  Multimodal Data Selection</h3>
                    <p><strong>Authors:</strong> Jinhe Bi, Yifan Wang, Danqi Yan, Xun Xiao, Artur Hecker, Volker Tresp, Yunpu Ma</p>
                    <p>  Visual instruction tuning refines pre-trained Multimodal Large Language
Models (MLLMs) to enhance their real-world task performance. However, the rapid
expansion of visual instruction datasets introduces significant data
redundancy, leading to excessive computational costs. Existing data selection
methods predominantly rely on proxy models or loss-based metrics, both of which
impose substantial computational overheads due to the necessity of model
inference and backpropagation. To address this challenge, we propose PRISM, a
novel training-free approach for efficient multimodal data selection. Unlike
existing methods, PRISM eliminates the reliance on proxy models, warm-up
pretraining, and gradient-based optimization. Instead, it leverages Pearson
correlation analysis to quantify the intrinsic visual encoding properties of
MLLMs, computing a task-specific correlation score to identify high-value
instances. This not only enbles data-efficient selection,but maintains the
original performance. Empirical evaluations across multiple MLLMs demonstrate
that PRISM reduces the overall time required for visual instruction tuning and
data selection to just 30% of conventional methods, while surpassing fully
fine-tuned models across eight multimodal and three language understanding
benchmarks, achieving a 101.7% relative improvement in final performance.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12119v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/17/2025</p>
                </li>
                <li>
                    <h3>Using the Path of Least Resistance to Explain Deep Networks</h3>
                    <p><strong>Authors:</strong> Sina Salek, Joseph Enguehard</p>
                    <p>  Integrated Gradients (IG), a widely used axiomatic path-based attribution
method, assigns importance scores to input features by integrating model
gradients along a straight path from a baseline to the input. While effective
in some cases, we show that straight paths can lead to flawed attributions. In
this paper, we identify the cause of these misattributions and propose an
alternative approach that treats the input space as a Riemannian manifold,
computing attributions by integrating gradients along geodesics. We call this
method Geodesic Integrated Gradients (GIG). To approximate geodesic paths, we
introduce two techniques: a k-Nearest Neighbours-based approach for smaller
models and a Stochastic Variational Inference-based method for larger ones.
Additionally, we propose a new axiom, Strong Completeness, extending the axioms
satisfied by IG. We show that this property is desirable for attribution
methods and that GIG is the only method that satisfies it. Through experiments
on both synthetic and real-world data, we demonstrate that GIG outperforms
existing explainability methods, including IG.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12108v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/17/2025</p>
                </li>
                <li>
                    <h3>Descriminative-Generative Custom Tokens for Vision-Language Models</h3>
                    <p><strong>Authors:</strong> Pramuditha Perera, Matthew Trager, Luca Zancato, Alessandro Achille, Stefano Soatto</p>
                    <p>  This paper explores the possibility of learning custom tokens for
representing new concepts in Vision-Language Models (VLMs). Our aim is to learn
tokens that can be effective for both discriminative and generative tasks while
composing well with words to form new input queries. The targeted concept is
specified in terms of a small set of images and a parent concept described
using text. We operate on CLIP text features and propose to use a combination
of a textual inversion loss and a classification loss to ensure that text
features of the learned token are aligned with image features of the concept in
the CLIP embedding space. We restrict the learned token to a low-dimensional
subspace spanned by tokens for attributes that are appropriate for the given
super-class. These modifications improve the quality of compositions of the
learned token with natural language for generating new scenes. Further, we show
that learned custom tokens can be used to form queries for text-to-image
retrieval task, and also have the important benefit that composite queries can
be visualized to ensure that the desired concept is faithfully encoded. Based
on this, we introduce the method of Generation Aided Image Retrieval, where the
query is modified at inference time to better suit the search intent. On the
DeepFashion2 dataset, our method improves Mean Reciprocal Retrieval (MRR) over
relevant baselines by 7%.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12095v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/17/2025</p>
                </li>
                <li>
                    <h3>A Study on Leveraging Search and Self-Feedback for Agent Reasoning</h3>
                    <p><strong>Authors:</strong> Karthikeyan K, Michelle Yuan, Elman Mansimov, Katerina Margatina, Anurag Pratik, Daniele Bonadiman, Monica Sunkara, Yi Zhang, Yassine Benajiba</p>
                    <p>  Recent works have demonstrated that incorporating search during inference can
significantly improve reasoning capabilities of language agents. Some
approaches may make use of the ground truth or rely on model's own generated
feedback. The search algorithm uses this feedback to then produce values that
will update its criterion for exploring and exploiting various reasoning paths.
In this study, we investigate how search and model's self-feedback can be
leveraged for reasoning tasks. First, we explore differences in ground-truth
feedback and self-feedback during search for math reasoning. Second, we observe
limitations in applying search techniques to more complex tasks like
tool-calling and design domain-specific approaches to address these gaps. Our
experiments reveal challenges related to generalization when solely relying on
self-feedback during search. For search to work effectively, either access to
the ground-truth is needed or feedback mechanisms need to be carefully designed
for the specific task.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12094v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/17/2025</p>
                </li>
                <li>
                    <h3>Meta-Statistical Learning: Supervised Learning of Statistical Inference</h3>
                    <p><strong>Authors:</strong> Maxime Peyrard, Kyunghyun Cho</p>
                    <p>  This work demonstrates that the tools and principles driving the success of
large language models (LLMs) can be repurposed to tackle distribution-level
tasks, where the goal is to predict properties of the data-generating
distribution rather than labels for individual datapoints. These tasks
encompass statistical inference problems such as parameter estimation,
hypothesis testing, or mutual information estimation. Framing these tasks
within traditional machine learning pipelines is challenging, as supervision is
typically tied to individual datapoint. We propose meta-statistical learning, a
framework inspired by multi-instance learning that reformulates statistical
inference tasks as supervised learning problems. In this approach, entire
datasets are treated as single inputs to neural networks, which predict
distribution-level parameters. Transformer-based architectures, without
positional encoding, provide a natural fit due to their permutation-invariance
properties. By training on large-scale synthetic datasets, meta-statistical
models can leverage the scalability and optimization infrastructure of
Transformer-based LLMs. We demonstrate the framework's versatility with
applications in hypothesis testing and mutual information estimation, showing
strong performance, particularly for small datasets where traditional neural
methods struggle.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.12088v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/17/2025</p>
                </li>
            </ul>
        </section>
    </main>
    <script src="scripts/papers.js"></script>
</body>
</html>