<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Papers</title>
    <link rel="stylesheet" href="styles/style.css">
</head>
<body>
    <div class="dog-container">
        <img src="images/dog.jpg" alt="My dog" class="dog-image">
        <p class="dog-caption">The guardian is observing</p>
    </div>
    <header>
        <h1>Papers</h1>
        <nav>
            <ul>
                <li><a href="main.html">Main (regular stuff)</a></li>
                <li><a href="games.html">Games (fun stuff)</a></li>
                <li><a href="papers.html">Papers (sciency stuff)</a></li>
                <li><a href="temperatures.html">Temperatures</a></li>
            </ul>
        </nav>
    </header>
    <main>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section id="papers-section">
            <h2>Latest Papers in Causal Inference</h2>
            <ul id="papersList">
                <li>
                    <h3>Mobile-MMLU: A Mobile Intelligence Language Understanding Benchmark</h3>
                    <p><strong>Authors:</strong> Sondos Mahmoud Bsharat, Mukul Ranjan, Aidar Myrzakhan, Jiacheng Liu, Bowei Guo, Shengkun Tang, Zhuang Liu, Yuanzhi Li, Zhiqiang Shen</p>
                    <p>  Rapid advancements in large language models (LLMs) have increased interest in
deploying them on mobile devices for on-device AI applications. Mobile users
interact differently with LLMs compared to desktop users, creating unique
expectations and data biases. Current benchmark datasets primarily target at
server and desktop environments, and there is a notable lack of extensive
datasets specifically designed for mobile contexts. Additionally, mobile
devices face strict limitations in storage and computing resources,
constraining model size and capabilities, thus requiring optimized efficiency
and prioritized knowledge. To address these challenges, we introduce
Mobile-MMLU, a large-scale benchmark dataset tailored for mobile intelligence.
It consists of 16,186 questions across 80 mobile-related fields, designed to
evaluate LLM performance in realistic mobile scenarios. A challenging subset,
Mobile-MMLU-Pro, provides advanced evaluation similar in size to MMLU-Pro but
significantly more difficult than our standard full set. Both benchmarks use
multiple-choice, order-invariant questions focused on practical mobile
interactions, such as recipe suggestions, travel planning, and essential daily
tasks. The dataset emphasizes critical mobile-specific metrics like inference
latency, energy consumption, memory usage, and response quality, offering
comprehensive insights into model performance under mobile constraints.
Moreover, it prioritizes privacy and adaptability, assessing models' ability to
perform on-device processing, maintain user privacy, and adapt to personalized
usage patterns. Mobile-MMLU family offers a standardized framework for
developing and comparing mobile-optimized LLMs, enabling advancements in
productivity and decision-making within mobile computing environments. Our code
and data are available at: https://github.com/VILA-Lab/Mobile-MMLU.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.20786v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/26/2025</p>
                </li>
                <li>
                    <h3>PUREPath-B: A Tessellated Bayesian Model for Recovering CMB B-modes over
  Large Angular Scales of the Sky</h3>
                    <p><strong>Authors:</strong> Vipin Sudevan, Pisin Chen</p>
                    <p>  We introduce a comprehensive, custom-developed neural network, the
PUREPath-B, that yields a posterior predictive distribution of Cosmic Microwave
Background (CMB) B-mode signal conditioned on the foreground contaminated CMB
data and informed by the training dataset. Our network employs nested
probabilistic multi-modal U-Net framework, enhanced with probabilistic ResNets
at skip connections and seamlessly integrates Bayesian statistics and
variational methods to minimize the foreground and noise contaminations. During
training, the initial prior distribution over network parameters evolves into
approximate posterior distributions through Bayesian inference, constrained by
the training data. From the approximate joint full posterior of the model
parameters, our network infers a predictive CMB posterior during inference and
yields summary statistics such as predictive mean, variance of the cleaned map.
The predictive standard deviation provides an interpretable measure of
per-pixel uncertainty in the predicted mean CMB map. For loss function, we use
a linear combination of KL-Divergence loss and weighted MAE-which ensures that
maps with higher amplitudes do not dominate the loss disproportionately.
Furthermore, the results from the cosmological parameter estimation using the
cleaned B-mode power spectrum, along with its error estimates demonstrates our
network minimizes the foreground contaminations effectively, enabling accurate
recovery of tensor-to-scalar ratio and lensing amplitude.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.20774v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/26/2025</p>
                </li>
                <li>
                    <h3>Inferring Treatment Effects in Large Panels by Uncovering Latent
  Similarities</h3>
                    <p><strong>Authors:</strong> Ben Deaner, Chen-Wei Hsiang, Andrei Zeleneev</p>
                    <p>  The presence of unobserved confounders is one of the main challenges in
identifying treatment effects. In this paper, we propose a new approach to
causal inference using panel data with large large $N$ and $T$. Our approach
imputes the untreated potential outcomes for treated units using the outcomes
for untreated individuals with similar values of the latent confounders. In
order to find units with similar latent characteristics, we utilize long
pre-treatment histories of the outcomes. Our analysis is based on a
nonparametric, nonlinear, and nonseparable factor model for untreated potential
outcomes and treatments. The model satisfies minimal smoothness requirements.
We impute both missing counterfactual outcomes and propensity scores using
kernel smoothing based on the constructed measure of latent similarity between
units, and demonstrate that our estimates can achieve the optimal nonparametric
rate of convergence up to log terms. Using these estimates, we construct a
doubly robust estimator of the period-specifc average treatment effect on the
treated (ATT), and provide conditions, under which this estimator is
$\sqrt{N}$-consistent, and asymptotically normal and unbiased. Our simulation
study demonstrates that our method provides accurate inference for a wide range
of data generating processes.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.20769v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/26/2025</p>
                </li>
                <li>
                    <h3>Reliable algorithm selection for machine learning-guided design</h3>
                    <p><strong>Authors:</strong> Clara Fannjiang, Ji Won Park</p>
                    <p>  Algorithms for machine learning-guided design, or design algorithms, use
machine learning-based predictions to propose novel objects with desired
property values. Given a new design task -- for example, to design novel
proteins with high binding affinity to a therapeutic target -- one must choose
a design algorithm and specify any hyperparameters and predictive and/or
generative models involved. How can these decisions be made such that the
resulting designs are successful? This paper proposes a method for design
algorithm selection, which aims to select design algorithms that will produce a
distribution of design labels satisfying a user-specified success criterion --
for example, that at least ten percent of designs' labels exceed a threshold.
It does so by combining designs' predicted property values with held-out
labeled data to reliably forecast characteristics of the label distributions
produced by different design algorithms, building upon techniques from
prediction-powered inference. The method is guaranteed with high probability to
return design algorithms that yield successful label distributions (or the null
set if none exist), if the density ratios between the design and labeled data
distributions are known. We demonstrate the method's effectiveness in simulated
protein and RNA design tasks, in settings with either known or estimated
density ratios.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.20767v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/26/2025</p>
                </li>
                <li>
                    <h3>MCTS-RAG: Enhancing Retrieval-Augmented Generation with Monte Carlo Tree
  Search</h3>
                    <p><strong>Authors:</strong> Yunhai Hu, Yilun Zhao, Chen Zhao, Arman Cohan</p>
                    <p>  We introduce MCTS-RAG, a novel approach that enhances the reasoning
capabilities of small language models on knowledge-intensive tasks by
leveraging retrieval-augmented generation (RAG) to provide relevant context and
Monte Carlo Tree Search (MCTS) to refine reasoning paths. MCTS-RAG dynamically
integrates retrieval and reasoning through an iterative decision-making
process. Unlike standard RAG methods, which typically retrieve information
independently from reasoning and thus integrate knowledge suboptimally, or
conventional MCTS reasoning, which depends solely on internal model knowledge
without external facts, MCTS-RAG combines structured reasoning with adaptive
retrieval. This integrated approach enhances decision-making, reduces
hallucinations, and ensures improved factual accuracy and response consistency.
The experimental results on multiple reasoning and knowledge-intensive datasets
datasets (i.e., ComplexWebQA, GPQA, and FoolMeTwice) show that our method
enables small-scale LMs to achieve performance comparable to frontier LLMs like
GPT-4o by effectively scaling inference-time compute, setting a new standard
for reasoning in small-scale models.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.20757v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/26/2025</p>
                </li>
                <li>
                    <h3>Benchmarking and optimizing organism wide single-cell RNA alignment
  methods</h3>
                    <p><strong>Authors:</strong> Juan Javier Diaz-Mejia, Elias Williams, Octavian Focsa, Dylan Mendonca, Swechha Singh, Brendan Innes, Sam Cooper</p>
                    <p>  Many methods have been proposed for removing batch effects and aligning
single-cell RNA (scRNA) datasets. However, performance is typically evaluated
based on multiple parameters and few datasets, creating challenges in assessing
which method is best for aligning data at scale. Here, we introduce the
K-Neighbors Intersection (KNI) score, a single score that both penalizes batch
effects and measures accuracy at cross-dataset cell-type label prediction
alongside carefully curated small (scMARK) and large (scREF) benchmarks
comprising 11 and 46 human scRNA studies respectively, where we have
standardized author labels. Using the KNI score, we evaluate and optimize
approaches for cross-dataset single-cell RNA integration. We introduce Batch
Adversarial single-cell Variational Inference (BA-scVI), as a new variant of
scVI that uses adversarial training to penalize batch-effects in the encoder
and decoder, and show this approach outperforms other methods. In the resulting
aligned space, we find that the granularity of cell-type groupings is
conserved, supporting the notion that whole-organism cell-type maps can be
created by a single model without loss of information.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.20730v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/26/2025</p>
                </li>
                <li>
                    <h3>Learning Straight Flows by Learning Curved Interpolants</h3>
                    <p><strong>Authors:</strong> Shiv Shankar, Tomas Geffner</p>
                    <p>  Flow matching models typically use linear interpolants to define the
forward/noise addition process. This, together with the independent coupling
between noise and target distributions, yields a vector field which is often
non-straight. Such curved fields lead to a slow inference/generation process.
In this work, we propose to learn flexible (potentially curved) interpolants in
order to learn straight vector fields to enable faster generation. We formulate
this via a multi-level optimization problem and propose an efficient
approximate procedure to solve it. Our framework provides an end-to-end and
simulation-free optimization procedure, which can be leveraged to learn
straight line generative trajectories.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.20719v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/26/2025</p>
                </li>
                <li>
                    <h3>Demand Estimation with Text and Image Data</h3>
                    <p><strong>Authors:</strong> Giovanni Compiani, Ilya Morozov, Stephan Seiler</p>
                    <p>  We propose a demand estimation method that leverages unstructured text and
image data to infer substitution patterns. Using pre-trained deep learning
models, we extract embeddings from product images and textual descriptions and
incorporate them into a random coefficients logit model. This approach enables
researchers to estimate demand even when they lack data on product attributes
or when consumers value hard-to-quantify attributes, such as visual design or
functional benefits. Using data from a choice experiment, we show that our
approach outperforms standard attribute-based models in counterfactual
predictions of consumers' second choices. We also apply it across 40 product
categories on Amazon.com and consistently find that text and image data help
identify close substitutes within each category.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.20711v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/26/2025</p>
                </li>
                <li>
                    <h3>Vision as LoRA</h3>
                    <p><strong>Authors:</strong> Han Wang, Yongjie Ye, Bingru Li, Yuxiang Nie, Jinghui Lu, Jingqun Tang, Yanjie Wang, Can Huang</p>
                    <p>  We introduce Vision as LoRA (VoRA), a novel paradigm for transforming an LLM
into an MLLM. Unlike prevalent MLLM architectures that rely on external vision
modules for vision encoding, VoRA internalizes visual capabilities by
integrating vision-specific LoRA layers directly into the LLM. This design
allows the added parameters to be seamlessly merged into the LLM during
inference, eliminating structural complexity and minimizing computational
overhead. Moreover, inheriting the LLM's ability of handling flexible context,
VoRA can process inputs at arbitrary resolutions.
  To further strengthen VoRA's visual capabilities, we introduce a block-wise
distillation method that transfers visual priors from a pre-trained ViT into
the LoRA layers, effectively accelerating training by injecting visual
knowledge. Additionally, we apply bi-directional attention masks to better
capture the context information of an image. We successfully demonstrate that
with additional pre-training data, VoRA can perform comparably with
conventional encode-based MLLMs. All training data, codes, and model weights
will be released at https://github.com/Hon-Wong/VoRA.
</p>
                    <p><a href="http://arxiv.org/pdf/2503.20680v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/26/2025</p>
                </li>
                <li>
                    <h3>Inductive Link Prediction on N-ary Relational Facts via Semantic
  Hypergraph Reasoning</h3>
                    <p><strong>Authors:</strong> Gongzhu Yin, Hongli Zhang, Yuchen Yang, Yi Luo</p>
                    <p>  N-ary relational facts represent semantic correlations among more than two
entities. While recent studies have developed link prediction (LP) methods to
infer missing relations for knowledge graphs (KGs) containing n-ary relational
facts, they are generally limited to transductive settings. Fully inductive
settings, where predictions are made on previously unseen entities, remain a
significant challenge. As existing methods are mainly entity embedding-based,
they struggle to capture entity-independent logical rules. To fill in this gap,
we propose an n-ary subgraph reasoning framework for fully inductive link
prediction (ILP) on n-ary relational facts. This framework reasons over local
subgraphs and has a strong inductive inference ability to capture n-ary
patterns. Specifically, we introduce a novel graph structure, the n-ary
semantic hypergraph, to facilitate subgraph extraction. Moreover, we develop a
subgraph aggregating network, NS-HART, to effectively mine complex semantic
correlations within subgraphs. Theoretically, we provide a thorough analysis
from the score function optimization perspective to shed light on NS-HART's
effectiveness for n-ary ILP tasks. Empirically, we conduct extensive
experiments on a series of inductive benchmarks, including transfer reasoning
(with and without entity features) and pairwise subgraph reasoning. The results
highlight the superiority of the n-ary subgraph reasoning framework and the
exceptional inductive ability of NS-HART. The source code of this paper has
been made publicly available at
https://github.com/yin-gz/Nary-Inductive-SubGraph.
</p>
                    <p><a href="http://arxiv.org/abs/2503.20676v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 3/26/2025</p>
                </li>
            </ul>
        </section>
    </main>
    <script src="scripts/papers.js"></script>
</body>
</html>