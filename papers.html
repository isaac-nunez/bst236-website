<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Papers</title>
    <link rel="stylesheet" href="styles/style.css">
</head>
<body>
    <div class="dog-container">
        <img src="images/dog.jpg" alt="My dog" class="dog-image">
        <p class="dog-caption">The guardian is observing</p>
    </div>
    <header>
        <h1>Papers</h1>
        <nav>
            <ul>
                <li><a href="main.html">Main (regular stuff)</a></li>
                <li><a href="games.html">Games (fun stuff)</a></li>
                <li><a href="papers.html">Papers (sciency stuff)</a></li>
            </ul>
        </nav>
    </header>
    <main>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <section id="papers-section">
            <h2>Latest Papers in Causal Inference</h2>
            <ul id="papersList">
                <li>
                    <h3>Embed Any NeRF: Graph Meta-Networks for Neural Tasks on Arbitrary NeRF
  Architectures</h3>
                    <p><strong>Authors:</strong> Francesco Ballerini, Pierluigi Zama Ramirez, Samuele Salti, Luigi Di Stefano</p>
                    <p>  Neural Radiance Fields (NeRFs) have emerged as a groundbreaking paradigm for
representing 3D objects and scenes by encoding shape and appearance information
into the weights of a neural network. Recent works have shown how such weights
can be used as input to frameworks processing them to solve deep learning
tasks. Yet, these frameworks can only process NeRFs with a specific, predefined
architecture. In this paper, we present the first framework that can ingest
NeRFs with multiple architectures and perform inference on architectures unseen
at training time. We achieve this goal by training a Graph Meta-Network in a
representation learning framework. Moreover, we show how a contrastive
objective is conducive to obtaining an architecture-agnostic latent space. In
experiments on both MLP-based and tri-planar NeRFs, our approach demonstrates
robust performance in classification and retrieval tasks that either matches or
exceeds that of existing frameworks constrained to single architectures, thus
providing the first architecture-agnostic method to perform tasks on NeRFs by
processing their weights.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.09623v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/13/2025</p>
                </li>
                <li>
                    <h3>LIFe-GoM: Generalizable Human Rendering with Learned Iterative Feedback
  Over Multi-Resolution Gaussians-on-Mesh</h3>
                    <p><strong>Authors:</strong> Jing Wen, Alexander G. Schwing, Shenlong Wang</p>
                    <p>  Generalizable rendering of an animatable human avatar from sparse inputs
relies on data priors and inductive biases extracted from training on large
data to avoid scene-specific optimization and to enable fast reconstruction.
This raises two main challenges: First, unlike iterative gradient-based
adjustment in scene-specific optimization, generalizable methods must
reconstruct the human shape representation in a single pass at inference time.
Second, rendering is preferably computationally efficient yet of high
resolution. To address both challenges we augment the recently proposed dual
shape representation, which combines the benefits of a mesh and Gaussian
points, in two ways. To improve reconstruction, we propose an iterative
feedback update framework, which successively improves the canonical human
shape representation during reconstruction. To achieve computationally
efficient yet high-resolution rendering, we study a coupled-multi-resolution
Gaussians-on-Mesh representation. We evaluate the proposed approach on the
challenging THuman2.0, XHuman and AIST++ data. Our approach reconstructs an
animatable representation from sparse inputs in less than 1s, renders views
with 95.1FPS at $1024 \times 1024$, and achieves PSNR/LPIPS*/FID of
24.65/110.82/51.27 on THuman2.0, outperforming the state-of-the-art in
rendering quality.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.09617v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/13/2025</p>
                </li>
                <li>
                    <h3>Variational Rectified Flow Matching</h3>
                    <p><strong>Authors:</strong> Pengsheng Guo, Alexander G. Schwing</p>
                    <p>  We study Variational Rectified Flow Matching, a framework that enhances
classic rectified flow matching by modeling multi-modal velocity vector-fields.
At inference time, classic rectified flow matching 'moves' samples from a
source distribution to the target distribution by solving an ordinary
differential equation via integration along a velocity vector-field. At
training time, the velocity vector-field is learnt by linearly interpolating
between coupled samples one drawn from the source and one drawn from the target
distribution randomly. This leads to ''ground-truth'' velocity vector-fields
that point in different directions at the same location, i.e., the velocity
vector-fields are multi-modal/ambiguous. However, since training uses a
standard mean-squared-error loss, the learnt velocity vector-field averages
''ground-truth'' directions and isn't multi-modal. In contrast, variational
rectified flow matching learns and samples from multi-modal flow directions. We
show on synthetic data, MNIST, CIFAR-10, and ImageNet that variational
rectified flow matching leads to compelling results.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.09616v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/13/2025</p>
                </li>
                <li>
                    <h3>SelfCite: Self-Supervised Alignment for Context Attribution in Large
  Language Models</h3>
                    <p><strong>Authors:</strong> Yung-Sung Chuang, Benjamin Cohen-Wang, Shannon Zejiang Shen, Zhaofeng Wu, Hu Xu, Xi Victoria Lin, James Glass, Shang-Wen Li, Wen-tau Yih</p>
                    <p>  We introduce SelfCite, a novel self-supervised approach that aligns LLMs to
generate high-quality, fine-grained, sentence-level citations for the
statements in their generated responses. Instead of only relying on costly and
labor-intensive annotations, SelfCite leverages a reward signal provided by the
LLM itself through context ablation: If a citation is necessary, removing the
cited text from the context should prevent the same response; if sufficient,
retaining the cited text alone should preserve the same response. This reward
can guide the inference-time best-of-N sampling strategy to improve citation
quality significantly, as well as be used in preference optimization to
directly fine-tune the models for generating better citations. The
effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3
points on the LongBench-Cite benchmark across five long-form question answering
tasks.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.09604v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/13/2025</p>
                </li>
                <li>
                    <h3>CoT-Valve: Length-Compressible Chain-of-Thought Tuning</h3>
                    <p><strong>Authors:</strong> Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, Xinchao Wang</p>
                    <p>  Chain-of-Thought significantly enhances a model's reasoning capability, but
it also comes with a considerable increase in inference costs due to long
chains. With the observation that the reasoning path can be easily compressed
under easy tasks but struggle on hard tasks, we explore the feasibility of
elastically controlling the length of reasoning paths with only one model,
thereby reducing the inference overhead of reasoning models dynamically based
on task difficulty. We introduce a new tuning and inference strategy named
CoT-Valve, designed to allow models to generate reasoning chains of varying
lengths. To achieve this, we propose to identify a direction in the parameter
space that, when manipulated, can effectively control the length of generated
CoT. Moreover, we show that this property is valuable for compressing the
reasoning chain. We construct datasets with chains from long to short for the
same questions and explore two enhanced strategies for CoT-Valve: (1) a precise
length-compressible CoT tuning method, and (2) a progressive chain length
compression approach. Our experiments show that CoT-Valve successfully enables
controllability and compressibility of the chain and shows better performance
than the prompt-based control. We applied this method to QwQ-32B-Preview,
reducing reasoning chains on GSM8K from 741 to 225 tokens with a minor
performance drop (95.07% to 94.92%) and on AIME from 6827 to 4629 tokens, with
only one additional incorrect answer.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.09601v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/13/2025</p>
                </li>
                <li>
                    <h3>A unique coupling of the massive spin-2 field to supergravity</h3>
                    <p><strong>Authors:</strong> Guillaume Bossard, Gabriele Casagrande, Emilian Dudas, Adrien Loty</p>
                    <p>  We show that the coupling of a massive spin-2 field to undeformed N=1
supergravity in four dimensions is unique, leading to a specific non-minimal
coupling to the Riemann tensor. The massive spin-2 coupling reproduces the one
of an oscillator mode in open string theory, while the massive spin-1 coupling
includes a higher-derivative term that is expected to violate causality in the
background of a gravitational shock wave. We argue that the resolution of
causality and the unitarity bound in the Regge limit require the introduction
of infinitely many higher-spin fields similar to the Regge trajectories in
string theory, therefore providing an argument in favour of the string lamppost
principle with minimal supersymmetry in four dimensions. To obtain this result,
we construct the general stress-energy tensor multiplet for the massive spin-2
multiplet with N=1 supersymmetry.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.09599v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/13/2025</p>
                </li>
                <li>
                    <h3>Do LLMs Recognize Your Preferences? Evaluating Personalized Preference
  Following in LLMs</h3>
                    <p><strong>Authors:</strong> Siyan Zhao, Mingyi Hong, Yang Liu, Devamanyu Hazarika, Kaixiang Lin</p>
                    <p>  Large Language Models (LLMs) are increasingly used as chatbots, yet their
ability to personalize responses to user preferences remains limited. We
introduce PrefEval, a benchmark for evaluating LLMs' ability to infer, memorize
and adhere to user preferences in a long-context conversational setting.
PrefEval comprises 3,000 manually curated user preference and query pairs
spanning 20 topics. PrefEval contains user personalization or preference
information in both explicit and implicit forms, and evaluates LLM performance
using a generation and a classification task. With PrefEval, we evaluated the
aforementioned preference following capabilities of 10 open-source and
proprietary LLMs in multi-session conversations with varying context lengths up
to 100k tokens. We benchmark with various prompting, iterative feedback, and
retrieval-augmented generation methods. Our benchmarking effort reveals that
state-of-the-art LLMs face significant challenges in proactively following
users' preferences during conversations. In particular, in zero-shot settings,
preference following accuracy falls below 10% at merely 10 turns (~3k tokens)
across most evaluated models. Even with advanced prompting and retrieval
methods, preference following still deteriorates in long-context conversations.
Furthermore, we show that fine-tuning on PrefEval significantly improves
performance. We believe PrefEval serves as a valuable resource for measuring,
understanding, and enhancing LLMs' preference following abilities, paving the
way for personalized conversational agents. Our code and dataset are available
at https://prefeval.github.io/.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.09597v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/13/2025</p>
                </li>
                <li>
                    <h3>Censor Dependent Variational Inference</h3>
                    <p><strong>Authors:</strong> Chuanhui Liu, Xiao Wang</p>
                    <p>  This paper provides a comprehensive analysis of variational inference in
latent variable models for survival analysis, emphasizing the distinctive
challenges associated with applying variational methods to survival data. We
identify a critical weakness in the existing methodology, demonstrating how a
poorly designed variational distribution may hinder the objective of survival
analysis tasks--modeling time-to-event distributions. We prove that the optimal
variational distribution, which perfectly bounds the log-likelihood, may depend
on the censoring mechanism. To address this issue, we propose censor-dependent
variational inference (CDVI), tailored for latent variable models in survival
analysis. More practically, we introduce CD-CVAE, a V-structure Variational
Autoencoder (VAE) designed for the scalable implementation of CDVI. Further
discussion extends some existing theories and training techniques to survival
analysis. Extensive experiments validate our analysis and demonstrate
significant improvements in the estimation of individual survival
distributions.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.09591v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/13/2025</p>
                </li>
                <li>
                    <h3>Star-crossed Clusters: Asteroseismic Ages for Individual Stars are in
  Tension with the Ages of their Host Clusters</h3>
                    <p><strong>Authors:</strong> Jamie Tayar, Meridith Joyce</p>
                    <p>  A meta-analysis of seismic ages determined for individual stars in the
well-studied open and globular clusters NGC 6819, NGC 6791, M67, M4, M19, M80,
and M9 reveals both high variance across measurements and significant
discrepancy with independent, isochrone-based age determinations for the
clusters in which these stars reside. The scatter among asteroseismic ages for
individual stars in any one of these clusters far surpasses both the absolute
age uncertainty computed for reference cluster M92 (5.4\%) and the
model-to-model systematic uncertainties in isochrones (roughly 10\%). This
suggests that either binary processes are significantly altering the masses of
stars in these clusters, or some additional corrections, perhaps as a function
of mass, metallicity, or surface gravity, are required to bring the
asteroseismic age scale into concordance with ages inferred from isochrone or
similar model fitting.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.09582v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/13/2025</p>
                </li>
                <li>
                    <h3>MorphNLI: A Stepwise Approach to Natural Language Inference Using Text
  Morphing</h3>
                    <p><strong>Authors:</strong> Vlad Andrei Negru, Robert Vacareanu, Camelia Lemnaru, Mihai Surdeanu, Rodica Potolea</p>
                    <p>  We introduce MorphNLI, a modular step-by-step approach to natural language
inference (NLI). When classifying the premise-hypothesis pairs into
{entailment, contradiction, neutral}, we use a language model to generate the
necessary edits to incrementally transform (i.e., morph) the premise into the
hypothesis. Then, using an off-the-shelf NLI model we track how the entailment
progresses with these atomic changes, aggregating these intermediate labels
into a final output. We demonstrate the advantages of our proposed method
particularly in realistic cross-domain settings, where our method always
outperforms strong baselines with improvements up to 12.6% (relative). Further,
our proposed approach is explainable as the atomic edits can be used to
understand the overall NLI label.
</p>
                    <p><a href="http://arxiv.org/pdf/2502.09567v1" target="_blank">Read PDF</a></p>
                    <p><strong>Submitted on:</strong> 2/13/2025</p>
                </li>
            </ul>
        </section>
    </main>
    <script src="scripts/papers.js"></script>
</body>
</html>